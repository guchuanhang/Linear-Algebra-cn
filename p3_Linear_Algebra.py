
# coding: utf-8

# # çº¿æ€§ä»£æ•°ï¼šæœºå™¨å­¦ä¹ èƒŒåçš„ä¼˜åŒ–åŸç†
# 
#         
# çº¿æ€§ä»£æ•°ä½œä¸ºæ•°å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå¹¿æ³›åº”ç”¨äºç§‘å­¦å’Œå·¥ç¨‹ä¸­ï¼ŒæŒæ¡å¥½çº¿æ€§ä»£æ•°å¯¹äºç†è§£å’Œä»äº‹æœºå™¨å­¦ä¹ ç®—æ³•ç›¸å…³å·¥ä½œæ˜¯å¾ˆæœ‰å¿…è¦çš„ï¼Œå°¤å…¶å¯¹äºæ·±åº¦å­¦ä¹ ç®—æ³•è€Œè¨€ã€‚å› æ­¤ï¼Œè¿™ä¸ªé¡¹ç›®ä¼šä»æµ…å…¥æ·±æ›´å¥½çš„å¸®åŠ©ä½ å­¦ä¹ ä¸ç§¯ç´¯ä¸€äº›è·Ÿäººå·¥æ™ºèƒ½å¼ºç›¸å…³çš„çº¿æ€§ä»£æ•°çš„çŸ¥è¯†ã€‚
# 
# æœ¬é¡¹ç›®å†…å®¹ç†è®ºçŸ¥è¯†éƒ¨åˆ†å‚è€ƒ[ã€ŠDeepLearningã€‹åˆåèŠ±ä¹¦](https://book.douban.com/subject/27087503/)ç¬¬äºŒç« ï¼Œå¸Œæœ›å¤§å®¶æ”¯æŒæ­£ç‰ˆè´­ä¹°å›¾ä¹¦ã€‚
# 
# è‹¥é¡¹ç›®ä¸­çš„é¢˜ç›®æœ‰å›°éš¾æ²¡å®Œæˆä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä»¬é¼“åŠ±ä½ å¸¦ç€é—®é¢˜æäº¤é¡¹ç›®ï¼Œè¯„å®¡äººä¼šç»™äºˆä½ è¯¸å¤šå¸®åŠ©ã€‚
# 
# æ‰€æœ‰é€‰åšé¢˜éƒ½å¯ä»¥ä¸åšï¼Œä¸å½±å“é¡¹ç›®é€šè¿‡ã€‚å¦‚æœä½ åšäº†ï¼Œé‚£ä¹ˆé¡¹ç›®è¯„å®¡ä¼šå¸®ä½ æ‰¹æ”¹ï¼Œä¹Ÿä¼šå› ä¸ºé€‰åšéƒ¨åˆ†åšé”™è€Œåˆ¤å®šä¸ºä¸é€šè¿‡ã€‚

# ## å‡†å¤‡å·¥ä½œ
# 
# æˆ‘ä»¬å°†è®²è§£å¸¸ç”¨çš„çº¿æ€§ä»£æ•°çŸ¥è¯†ï¼Œè€Œå­¦å‘˜éœ€ä½¿ç”¨numpyæ¥å®ç°è¿™äº›çŸ¥è¯†ç‚¹ï¼ˆå½“ç„¶ä¹Ÿå¯ä»¥è‡ªå·±å†™ç®—æ³•å®ç°ï¼‰ï¼Œè¿˜éœ€è¦ä½¿ç”¨matplotlibå®Œæˆè§„å®šå›¾åƒä¹ é¢˜ï¼Œå½“ç„¶ï¼Œæœ¬é¡¹ç›®ç”¨åˆ°çš„pythonä»£ç (æˆ–numpyçš„ä½¿ç”¨)è¯¾ç¨‹ä¸­å¹¶æœªå®Œå…¨æ•™æˆï¼Œæ‰€ä»¥éœ€è¦å­¦å‘˜å¯¹ç›¸åº”æ“ä½œè¿›è¡Œå­¦ä¹ ä¸æŸ¥è¯¢ï¼Œè¿™åœ¨æˆ‘ä»¬å¾€åçš„äººå·¥æ™ºèƒ½å­¦ä¹ ä¹‹æ—…ä¸­æ˜¯å¿…ä¸å¯å°‘çš„ä¸€ä¸ªæŠ€èƒ½ï¼Œè¯·å¤§å®¶çæƒœæ­¤é¡¹ç›®çš„ç»ƒä¹ æœºä¼šã€‚
# 
# å½“ç„¶ï¼Œè¿™é‡Œæä¾›å®˜æ–¹çš„[numpy Quickstart](https://docs.scipy.org/doc/numpy/user/quickstart.html#)æ¥å¸®åŠ©ä½ æ›´å¥½çš„å®Œæˆé¡¹ç›®ã€‚
# 
# æœ¬é¡¹ç›®è¿˜éœ€è¦ä½¿ç”¨LaTeXå…¬å¼ï¼Œä»¥ä¸‹ä¸¤ä¸ªé“¾æ¥ä¾›å­¦ä¹ ä¸ä½¿ç”¨ï¼š
# 
# [Latex cheatsheet](https://www.authorea.com/users/77723/articles/110898-how-to-write-mathematical-equations-expressions-and-symbols-with-latex-a-cheatsheet)
# 
# [aTeX Cookbook](http://www.personal.ceu.hu/tex/cookbook.html#inline)
# 
# é¦–å…ˆï¼Œå¯¼å…¥ä½ æ‰€éœ€çš„è½¯ä»¶åŒ…ã€‚ä¸€èˆ¬æˆ‘ä»¬å»ºè®®åœ¨å·¥ç¨‹å¼€å¤´å¯¼å…¥**æ‰€æœ‰**éœ€è¦çš„è½¯ä»¶åŒ…ã€‚

# In[1]:


# DONE: importç›¸å…³åº“
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import Latex
from PIL import Image


# ## 1ã€æ ‡é‡ï¼Œå‘é‡ï¼ŒçŸ©é˜µï¼Œå¼ é‡

# **é¦–å…ˆï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸‹åŸºæœ¬çš„å®šä¹‰ï¼š**
# 
# - æ ‡é‡ï¼ˆscalarï¼‰ï¼šå½¢å¼è€Œè¨€ï¼Œä¸€ä¸ªæ ‡é‡æ˜¯ä¸€ä¸ªå•ç‹¬çš„æ•°ï¼Œå¸¸ç”¨æ–œä½“çš„å°å†™å˜é‡åç§°æ¥è¡¨ç¤ºã€‚_v_
# 
# - å‘é‡ï¼ˆvectorï¼‰ï¼šå½¢å¼è€Œè¨€ï¼Œä¸€ä¸ªå‘é‡æ˜¯ä¸€åˆ—æœ‰åºæ•°ï¼Œå¸¸ç”¨ç²—ä½“çš„å°å†™å˜é‡åç§°è¡¨ç¤º**v**ï¼Œæˆ–è€…ä¸Šé¢æ ‡è®°å‰ªå¤´$\vec{v}$ 
# 
# - çŸ©é˜µï¼ˆmatrixï¼‰ï¼šå½¢å¼è€Œè¨€ï¼Œä¸€ä¸ªçŸ©é˜µæ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œå¸¸ç”¨å¤§å†™å˜é‡åç§°è¡¨ç¤ºAï¼Œè¡¨ç¤ºå†…éƒ¨çš„å…ƒç´ åˆ™ä¼šä½¿ç”¨$A_{i,j}$
# 
# - å¼ é‡ï¼ˆtensorï¼‰ï¼šå½¢å¼è€Œè¨€ï¼Œä¸€ä¸ªå¼ é‡æ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œå¸¸ç”¨ç²—ä½“çš„å¤§å†™å­—æ¯å˜é‡åç§°è¡¨ç¤º**T**ï¼Œè¡¨ç¤ºå†…éƒ¨çš„å…ƒç´ åˆ™ä¼šä½¿ç”¨$A_{i,j,z}$ ç­‰ç­‰
# 
# ç”¨å›¾ç‰‡ç›´è§‚çš„æ˜¾ç¤ºåŒºåˆ«å¦‚ä¸‹
# <img src="images/diff.png" width="500">
# 
# **æ¥ä¸‹æ¥è®©æˆ‘ä»¬å›é¡¾ä¸‹åŸºæœ¬çš„è¿ç®—ï¼š**
# 
# - åŠ æ³•
# <img src="images/add.png" width="500">
# 
# - æ ‡é‡ä¹˜æ³•
# <img src="images/scmu.png" width="400">
# 
# - è½¬ç½®
# <img src="images/trans.png" width="370">
# 
# - çŸ©é˜µå‘é‡ä¹˜æ³•ï¼ˆå†…ç§¯ï¼Œäººå·¥æ™ºèƒ½ä¸­å¸¸è§çš„æ‹¼å†™ï¼šmatrix product æˆ–è€… dot productï¼‰ 
# <img src="images/mul.png" width="570">
# 
# **çº¿æ€§æ–¹ç¨‹ç»„ï¼š**
# 
# ç”±çŸ©é˜µä¹˜æ³•ä¹Ÿæ¼”å˜å‡ºäº†æˆ‘ä»¬æœ€å¸¸è§çš„çº¿æ€§æ–¹ç¨‹ç»„ï¼Œå·²çŸ¥çŸ©é˜µä¸æœªçŸ¥å‘é‡çš„ä¹˜ç§¯ï¼Œç­‰äºå¦ä¸€ä¸ªå·²çŸ¥å‘é‡ï¼Œé€šè¿‡æ­¤æ–¹ç¨‹ç»„å¯æ±‚è§£é‚£ä¸ªæœªçŸ¥å‘é‡ï¼Œä¸€èˆ¬å†™ä¸ºxï¼Œå…·ä½“å¦‚ä¸‹è¡¨ç¤ºã€‚
# ç­‰å¼å·¦ä¾§å¯ä»¥è¿™ä¹ˆæ¥ç†è§£ï¼š
# <img src="images/axb.png" width="400">
# åˆ—ä¸ºå…·ä½“çš„çŸ©é˜µæ¥çœ‹ï¼š
# $$
# \begin{bmatrix}
#     A_{1,1} & A_{1,2} & \cdots & A_{1,n} \\\\
#     A_{2,1} & A_{2,2} & \cdots & A_{2,n} \\\\
#     \cdots & \cdots & \cdots & \cdots \\\\
#     A_{m,1} & A_{m,2} & \cdots & A_{m,n}
# \end{bmatrix}
# \times
# \begin{bmatrix}
#     x_1 \\\\
#     x_2 \\\\
#     \cdots \\\\
#     x_n
# \end{bmatrix}
# =
# \begin{bmatrix}
#     b_1 \\\\
#     b_2 \\\\
#     \cdots \\\\
#     b_m
# \end{bmatrix}
# $$
# 
# æˆ–è€…æ›´ç®€å•çš„è¡¨ç¤ºä¸º
# 
# $$Ax=b$$
# 
# æ—¢ç„¶æœ‰æœªçŸ¥æ•°ï¼Œé‚£ä¹ˆè‡ªç„¶éœ€è¦æ±‚è§£æœªçŸ¥æ•°ï¼Œè€Œæˆ‘ä»¬çš„æœªçŸ¥æ•°éœ€è¦æ»¡è¶³æ‰€æœ‰æ–¹ç¨‹ï¼Œä¹Ÿä¸æ˜¯ä¸€ç›´éƒ½æœ‰è§£çš„ï¼Œä¸‹é¢æ¥åˆ—æˆ‘ä»¬äºŒç»´çŸ©é˜µæ‰€ç»„æˆçš„æ–¹ç¨‹è§£çš„æƒ…å†µ,è‹¥ä¸¤æ¡çº¿å¹³è¡Œä¸å­˜åœ¨ç„¦ç‚¹ï¼Œé‚£ä¹ˆè¯´æ˜æ²¡æœ‰ä¸€ä¸ª$x_1$, $x_2$åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ–¹ç¨‹ï¼Œåˆ™æ­¤æ–¹ç¨‹ç»„æ— è§£ï¼ŒåŒç†ï¼Œè‹¥ç›¸äº¤ï¼Œåˆ™æœ‰ä¸€ä¸ªè§£ï¼Œè‹¥å®Œå…¨ç›¸ç­‰ï¼Œåˆ™æœ‰æ— ç©·ä¸ªè§£ã€‚
# <img src="images/axbsolu.png" width="570">

# ### 1.1ã€åŸºæœ¬è¿ç®—å¹¶ç»˜å›¾
# ä¾‹é¢˜ $\vec{v}$ + $\vec{w}$
# 
# $\hspace{1cm}\vec{v} = \begin{bmatrix} 1\\ 1\end{bmatrix}$
# 
# 
# $\hspace{1cm}\vec{w} = \begin{bmatrix} -2\\ 2\end{bmatrix}$
# 
# ç»“æœéœ€è¦å…ˆä½¿ç”¨numpyè®¡ç®—å‘é‡è¿ç®—ç»“æœï¼Œå¹¶ç”¨LaTeXå…¬å¼è¡¨ç¤ºï¼š
# 
# $\hspace{1cm}\vec{v}+\vec{w} = \begin{bmatrix} -1\\ 3\end{bmatrix}$
# 
# å¹¶ä½¿ç”¨matlibplotç»˜åˆ¶å‡º(å›¾è¡¨é¢œè‰²æ ·å¼ä¸è¦æ±‚)
# 
# <img src="images/add_e.png" width="300">
# 
# #### 1.1.1
# **æ ¹æ®ä¸Šé¢ä¾‹é¢˜å±•ç¤ºï¼Œè®¡ç®—å¹¶ç»˜åˆ¶  $2\vec{v}$ - $\vec{w}$  çš„ç»“æœ**
# 
# $\hspace{1cm}\vec{v} = \begin{bmatrix} 4\\ 1\end{bmatrix}$
# 
# 
# $\hspace{1cm}\vec{w} = \begin{bmatrix} -1\\ 2\end{bmatrix}$
# 
# 

# In[2]:


# 1.1.1 DONEï¼š
# Define vector v 
v = np.array([1,1])
# Define vector w
w = np.array([-2,2])

target_v = 2 * v

target_w = (-1) * w

target = target_v + target_w
# Creates axes of plot referenced 'ax'
ax = plt.axes()

# Plots red dot at origin (0,0)
ax.plot(0,0,'or')


# Plots vector v_ihat as dotted green arrow starting at origin 0,0
ax.arrow(0, 0, *target_v, color='g', linestyle='dotted', linewidth=2.5, head_width=0.30,
         head_length=0.35)

# Plots vector v_jhat as dotted red arrow starting at origin defined by v_ihat
ax.arrow(target_v[0], target_v[1], *target_w, color='r', linestyle='dotted', linewidth=2.5,
         head_width=0.30, head_length=0.35)

# Plots vector v as blue arrow starting at origin 0,0
ax.arrow(0, 0, *target, color='b', linewidth=2.5, head_width=0.30, head_length=0.35)


# Sets limit for plot for x-axis
plt.xlim(-2, 8)

# Set major ticks for x-axis
major_xticks = np.arange(-2,8)
ax.set_xticks(major_xticks)


# Sets limit for plot for y-axis
plt.ylim(-2, 4)

# Set major ticks for y-axis
major_yticks = np.arange(-2, 4)
ax.set_yticks(major_yticks)

# Creates gridlines for only major tick marks
plt.grid(b=True, which='major')

# Displays final plot
plt.show()


# ä¾‹é¢˜ï¼Œæ–¹ç¨‹ç»„æ±‚è§£ï¼š
# $$
# \begin{cases}
# y = 2x + 1\\\\
# y = 6x - 2
# \end{cases}
# $$
# ç”¨matplotlibç»˜åˆ¶å›¾è¡¨ï¼ˆå›¾è¡¨æ ·å¼ä¸è¦æ±‚ï¼‰
# <img src="images/2equ_solu.png" width="300">
# ç”±ä¸Šå¯çŸ¥æ­¤æ–¹ç¨‹ç»„æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªè§£
# 
# éœ€ä½¿ç”¨numpyï¼ˆæˆ–è‡ªå†™ç®—æ³•ï¼‰è®¡ç®—è¯¥è§£çš„ç»“æœ,å¹¶ç”¨LaTeXå…¬å¼è¡¨ç¤ºå‡ºæ¥(ç»“æœå¯ä»¥ç”¨å°æ•°æˆ–è€…åˆ†æ•°å±•ç¤º)
# $$
# \begin{cases}
# x = \frac{3}{4} \\\\
# y = \frac{5}{2}
# \end{cases}
# $$
# 
# 
# #### 1.1.2 
# **æ ¹æ®ä¸Šé¢ä¾‹é¢˜å±•ç¤ºï¼Œç»˜åˆ¶æ–¹ç¨‹ç»„ï¼Œè¯´æ˜æ˜¯å¦æœ‰è§£æ˜¯å¦ä¸ºå”¯ä¸€è§£ï¼Œè‹¥æœ‰è§£éœ€è®¡ç®—å‡ºæ–¹ç¨‹ç»„çš„è§£**
# $$
# \begin{cases}
# y = 2x + 1\\\\
# y = \frac{1}{10}x+6
# \end{cases}
# $$

# In[3]:


# 1.1.2 DONE
t = np.arange(-4, 10, 2)
y1 = 2 * t + 1
y2 = 0.1 * t + 6

ax = plt.axes()
line1 = ax.plot(t, y1, lw=2, color='red')
line2 = ax.plot(t, y2, lw=2, color='blue')

# Sets limit for plot for x-axis
plt.xlim(-2, 8)

# Set major ticks for x-axis
major_xticks = np.arange(-2,8,2)
ax.set_xticks(major_xticks)


# Sets limit for plot for y-axis
plt.ylim(-2, 8)

# Set major ticks for y-axis
major_yticks = np.arange(-2, 8,2)
ax.set_yticks(major_yticks)

plt.grid(b=True, which='major')
plt.show()
#ç”±å›¾çŸ¥æ­¤æ–¹ç¨‹ç»„æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªè§£
a = np.array([[2,-1], [0.1,-1]])
b = np.array([-1, -6])
intersection = np.linalg.solve(a, b)
print(intersection)
Latex(r"\begin{equation} \begin{cases} x =2.63157895 \\  y =6.26315789\end{cases}\end{equation}")


# ### 1.2ã€è¯´æ˜é¢˜
# #### 1.2.1
# **ä½¿ç”¨numpyï¼ˆæˆ–è‡ªå†™ç®—æ³•ï¼‰è¯´æ˜$(AB)^{\text{T}} = B^\text{T}A^\text{T}$**
# 
# **å…¶ä¸­**
# $$
# A=\begin{bmatrix}
#     21 & 7 \\\\
#     15 & 42 \\\\
#     9 & 6
# \end{bmatrix}, 
# B=\begin{bmatrix}
#     4 \\\\
#     33
# \end{bmatrix}
# $$

# In[4]:


# 1.2.1 DONE
A = np.array([[21, 15, 9],[7, 42, 6]])
B = np.array([4, 33])
AB = np.matmul(B, A)
#(ğ´ğµ)T
AB_transpose = AB.transpose()
B_transpose = B.transpose()
A_transpose = A.transpose()
#ğµTğ´T
B_tran_A_tran =  np.matmul(A_transpose,B_transpose)
is_equal = ((AB_transpose == B_tran_A_tran).all())
if is_equal:
    print("(ğ´ğµ)T=ğµTğ´T")
else:
    print("(ğ´ğµ)T!=ğµTğ´T")


# #### 1.2.2
# **ä½¿ç”¨numpyï¼ˆæˆ–è‡ªå†™ç®—æ³•ï¼‰è¯´æ˜  $A ( B + C ) = AB + AC$ **
# 
# **å…¶ä¸­**
# $$
# A=\begin{bmatrix}
#     9 & 3 \\\\
#     8 & 4 \\\\
#     7 & 6
# \end{bmatrix}, 
# B=\begin{bmatrix}
#     5 \\\\
#     2
# \end{bmatrix}, 
# C=\begin{bmatrix}
#     5 \\\\
#     7
# \end{bmatrix}
# $$

# In[5]:


# 1.2.2 DONE
A = np.array([[9, 8, 7], [3, 4, 6]])
B = np.array([5, 2])
C = np.array([5, 7])
left_result = np.matmul((B + C), A)
right_result = np.matmul(B, A) + np.matmul(C, A)
is_equal = ((left_result == right_result).all())
if is_equal:
    print("ğ´(ğµ+ğ¶)=ğ´ğµ+ğ´ğ¶")
else:
    print("ğ´(ğµ+ğ¶)!=ğ´ğµ+ğ´ğ¶T")


# ## 2ã€ç‰¹æ®ŠçŸ©é˜µ

# - å•ä½çŸ©é˜µ
# 
# å¦‚æœé€‰å–ä»»æ„ä¸€ä¸ªå‘é‡å’ŒæŸçŸ©é˜µç›¸ä¹˜ï¼Œè¯¥å‘é‡éƒ½ä¸ä¼šæ”¹å˜ï¼Œæˆ‘ä»¬å°†è¿™ç§ä¿æŒnç»´å‘é‡ä¸å˜çš„çŸ©é˜µè®°ä¸ºå•ä½çŸ©é˜µ$I_n$
# 
# - é€†çŸ©é˜µ
# 
# å¦‚æœå­˜åœ¨ä¸€ä¸ªçŸ©é˜µï¼Œä½¿$A^{-1} A = I_n$ï¼Œé‚£ä¹ˆ$A^{-1}$å°±æ˜¯Açš„é€†çŸ©é˜µã€‚
# 
# - å¯¹è§’çŸ©é˜µ
# 
# å¦‚æœä¸€ä¸ªçŸ©é˜µåªæœ‰ä¸»å¯¹è§’çº¿ä¸Šè¿˜æœ‰éé›¶å…ƒç´ ï¼Œå…¶ä»–ä½ç½®éƒ½æ˜¯é›¶ï¼Œè¿™ä¸ªçŸ©é˜µå°±æ˜¯å¯¹è§’çŸ©é˜µ
# 
# - å¯¹ç§°çŸ©é˜µ
# 
# å¦‚æœä¸€ä¸ªçŸ©é˜µçš„è½¬ç½®æ˜¯å’Œå®ƒè‡ªå·±ç›¸ç­‰çš„çŸ©é˜µï¼Œå³$A=A^{T}$ï¼Œé‚£ä¹ˆè¿™ä¸ªçŸ©é˜µå°±æ˜¯å¯¹ç§°çŸ©é˜µ
# 
# - æ­£äº¤çŸ©é˜µ
# 
# è¡Œå‘é‡å’Œåˆ—å‘é‡æ˜¯åˆ†åˆ«æ ‡å‡†æ­£äº¤(90åº¦)çš„æ–¹é˜µï¼Œå³$A^{T}A = AA^{T} = I_n$ï¼Œåˆå³$A^{-1} = A^{T}$ï¼Œé‚£ä¹ˆè¿™ç§æ–¹é˜µå°±æ˜¯æ­£äº¤çŸ©é˜µ
# 
# 
# 
# 
# ### 2.1ã€è¯æ˜é¢˜
# 
# é€šè¿‡LaTeXå…¬å¼ï¼Œç»“åˆä¸Šé¢æ‰€è¿°æ¦‚å¿µï¼Œå‡è®¾$A^{-1}$å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œè¯æ˜$Ax=b$çš„è§£$x={A}^{-1}{b}$

# å›ç­”ï¼š
# 

# A^{-1}*Ax = A^{-1}*b
# x =A^{-1}*b

# ### 2.2ã€ è®¡ç®—é¢˜
# 
# #### 2.2.1
# 
# é€šè¿‡numpyè®¡ç®—ï¼Œå†æ¬¡éªŒè¯2.1è¯æ˜é¢˜
# $$
# \begin{cases}
# y = 2x + 1\\\\
# y = \frac{1}{10}x+6
# \end{cases}
# $$
# å¹¶ç”¨LaTeXå…¬å¼å†™å‡º$A^{-1}$æ˜¯å¤šå°‘ï¼ˆå°æ•°åˆ†æ•°çš†å¯ï¼‰

# In[6]:


# 2.2.1 DONE
matrix_A = np.array([[1, 1], [-2, -0.1]])
vec_b = np.array([1, 6])
matrix_A_inv = np.linalg.inv(matrix_A)
print(matrix_A_inv)
vec_x = np.matmul(matrix_A_inv, vec_b)
matrix_A_x = np.matmul(matrix_A, vec_x)
# print(type(matrix_A_x[0]))
# print(type(vec_b[0]))
# print(matrix_A_x)
# print(vec_b)
round_matrix_A_x = np.round(matrix_A_x)
print(vec_b)
print(round_matrix_A_x)

is_equal = ((round_matrix_A_x == vec_b).all())
if is_equal:
    print("ğ´ğ‘¥=ğ‘ çš„è§£ ğ‘¥=ğ´^(âˆ’1)ğ‘")
else:
    print("ğ´ğ‘¥=ğ‘ çš„è§£ ğ‘¥!=ğ´^(âˆ’1)ğ‘")

# Latex(r"$$\begin{matrix} -0.05263158 & 1.05263158 \\-0.52631579 & 0.52631579 \end{matrix} \tag{1}$$")
Latex(r"A$^{-1}$ is:  $$\begin{matrix} -0.05263158 & 1.05263158 \\-0.52631579 & 0.52631579 \end{matrix} \tag{1}$$")


# #### 2.2.2
# 
# 1ã€è¯·ç”¨numpyï¼ˆæˆ–è‡ªå†™ç®—æ³•ï¼‰å®ç°ä¸€ä¸ª6x6çš„å¯¹è§’çŸ©é˜µï¼ŒçŸ©é˜µçš„å¯¹è§’çº¿ç”±3è‡³8ï¼ˆå«8ï¼‰ç»„æˆã€‚
# 
# 2ã€è®¡ç®—ç¬¬ä¸€é—®ç”Ÿæˆçš„å¯¹è§’çŸ©é˜µä¸å‘é‡$[6,7,1,2,5,9]^{T}$çš„ä¹˜ç§¯

# In[7]:


# 2.2.2 DONE
vec_v = np.arange(3,9)
matrix_X = np.diag(vec_v)   
# print(matrix_X)
vec_x = np.array([6,7,1,2,5,9])
transpose_vec_x = vec_x.transpose()
# print(type(transpose_vec_x))
# print(np.shape(vec_x))
# print(np.shape(transpose_vec_x.shape))
result = np.matmul(transpose_vec_x, matrix_X)
print(result)


# ## 3ã€è¿¹è¿ç®—
# è¿¹è¿ç®—è¿”å›çš„æ˜¯çŸ©é˜µå¯¹è§’å…ƒç´ çš„å’Œï¼Œå¦‚å›¾æ‰€ç¤º
# <img src="images/matrix.png" width="360">
# å†™æˆæ•°å­¦å…¬å¼ä¸ºï¼š
# $$ \large Tr(A) = \sum_{i}A_{i,i}$$
# 
# **è¯´æ˜é¢˜ï¼š**
# 
# ä½¿ç”¨numpyéªŒè¯
# $$
# \large Tr(ABC) = Tr(CAB) = Tr(BCA)
# $$
# å…¶ä¸­
# $$
# A=
# \begin{bmatrix}
#     7 & 6 \\\\
#     29 & 3
# \end{bmatrix}
# $$
# 
# $$
# B=
# \begin{bmatrix}
#     2 & -8 \\\\
#     9 & 10
# \end{bmatrix}
# $$
# 
# $$
# C=
# \begin{bmatrix}
#     2 & 17 \\\\
#     1 & 5
# \end{bmatrix}
# $$

# In[8]:


# 3 DONE
matrix_A = np.array([[7, 29], [6, 3]])
matrix_B = np.array([[2, 9], [-8, 10]])
matrix_C = np.array([[2, 1], [17, 5]])
matrix_ABC = np.matmul(np.matmul(matrix_A, matrix_B), matrix_C)
matrix_CAB = np.matmul(np.matmul(matrix_C ,matrix_A ),matrix_B)
matrix_BCA = np.matmul(np.matmul(matrix_B ,matrix_C ),matrix_A)
Tr_ABC = matrix_ABC.diagonal().sum()
Tr_CAB = matrix_CAB.diagonal().sum()
Tr_BCA = matrix_BCA.diagonal().sum()
if Tr_ABC == Tr_CAB ==Tr_BCA:
    print("ğ‘‡ğ‘Ÿ(ğ´ğµğ¶)=ğ‘‡ğ‘Ÿ(ğ¶ğ´ğµ)=ğ‘‡ğ‘Ÿ(ğµğ¶ğ´)")
else:
    print("ğ‘‡ğ‘Ÿ(ğ´ğµğ¶)=ğ‘‡ğ‘Ÿ(ğ¶ğ´ğµ)=ğ‘‡ğ‘Ÿ(ğµğ¶ğ´) is wrong")


# ## 4ã€è¡¡é‡å‘é‡ä»¥åŠçŸ©é˜µçš„å¤§å°ï¼šèŒƒæ•°ä¸æ¡ä»¶æ•°
# 
# ### èŒƒæ•°çš„å®šä¹‰
# 
# åœ¨çº¿æ€§ä»£æ•°ç­‰æ•°å­¦åˆ†æ”¯ä¸­ï¼ŒèŒƒæ•°ï¼ˆNormï¼‰æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå…¶ç»™äºˆæŸå‘é‡ç©ºé—´ï¼ˆæˆ–çŸ©é˜µï¼‰ä¸­çš„æ¯ä¸ªå‘é‡ä»¥é•¿åº¦æˆ–ç§°ä¹‹ä¸ºå¤§å°ã€‚å¯¹äºé›¶å‘é‡ï¼Œå…¶é•¿åº¦ä¸ºé›¶ã€‚ç›´è§‚çš„è¯´ï¼Œå‘é‡æˆ–çŸ©é˜µçš„èŒƒæ•°è¶Šå¤§ï¼Œåˆ™æˆ‘ä»¬å¯ä»¥è¯´è¿™ä¸ªå‘é‡æˆ–çŸ©é˜µä¹Ÿå°±è¶Šå¤§ã€‚æœ‰æ—¶èŒƒæ•°æœ‰å¾ˆå¤šæ›´ä¸ºå¸¸è§çš„å«æ³•ï¼Œå¦‚ç»å¯¹å€¼å…¶å®ä¾¿æ˜¯ä¸€ç»´å‘é‡ç©ºé—´ä¸­å®æ•°æˆ–å¤æ•°çš„èŒƒæ•°ï¼ŒèŒƒæ•°çš„ä¸€èˆ¬åŒ–å®šä¹‰ï¼šè®¾$p\ge 1$ï¼Œp-normç”¨ä»¥ä¸‹æ¥è¡¨ç¤º
# 
# 
# $$ \large {\Vert x \Vert}_{p} =  \lgroup {\sum_{i}{\vert x_i \vert}^p }\rgroup ^{\frac{1}{p}}$$
# 
# æ­¤å¤„ï¼Œå½“p=1æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹æ›¼å“ˆé¡¿èŒƒæ•°(Manhattan Norm)ã€‚å…¶æ¥æºæ˜¯æ›¼å“ˆé¡¿çš„å‡ºç§Ÿè½¦å¸æœºåœ¨å››å››æ–¹æ–¹çš„æ›¼å“ˆé¡¿è¡—é“ä¸­ä»ä¸€ç‚¹åˆ°å¦ä¸€ç‚¹æ‰€éœ€è¦èµ°è¿‡çš„è·ç¦»ã€‚ä¹Ÿå³æˆ‘ä»¬æ‰€è¦è®¨è®ºçš„L1èŒƒæ•°ã€‚å…¶è¡¨ç¤ºæŸä¸ªå‘é‡ä¸­æ‰€æœ‰å…ƒç´ ç»å¯¹å€¼çš„å’Œã€‚ è€Œå½“p=2æ—¶ï¼Œåˆ™æ˜¯æˆ‘ä»¬æœ€ä¸ºå¸¸è§çš„Euclidean normã€‚ä¹Ÿç§°ä¸ºEuclidean distanceï¼Œä¸­æ–‡å«æ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼Œä¹Ÿå³æˆ‘ä»¬è¦è®¨è®ºçš„L2èŒƒæ•°ï¼Œä»–ä¹Ÿç»å¸¸è¢«ç”¨æ¥è¡¡é‡å‘é‡çš„å¤§å°ã€‚ è€Œå½“p=0æ—¶ï¼Œä¸¥æ ¼çš„è¯´æ­¤æ—¶på·²ä¸ç®—æ˜¯èŒƒæ•°äº†ï¼ŒL0èŒƒæ•°æ˜¯æŒ‡å‘é‡ä¸­é0çš„å…ƒç´ çš„ä¸ªæ•°ï¼Œä½†å¾ˆå¤šäººä»ç„¶ç§°ä¹‹ä¸ºL0èŒƒæ•°ï¼ˆZero normé›¶èŒƒæ•°ï¼‰ã€‚ è¿™ä¸‰ä¸ªèŒƒæ•°æœ‰å¾ˆå¤šéå¸¸æœ‰æ„æ€çš„ç‰¹å¾ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨å­¦ä¹ ä¸­çš„æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰ä»¥åŠç¨€ç–ç¼–ç ï¼ˆSparse Codingï¼‰æœ‰éå¸¸æœ‰è¶£çš„åº”ç”¨ï¼Œè¿™ä¸ªåœ¨è¿›é˜¶è¯¾ç¨‹å¯ä»¥åšæ›´æ·±å…¥çš„äº†è§£ã€‚
# 
# **L0 èŒƒæ•°**
# $$ \large \Vert x \Vert = \sqrt[0]{\sum_i x_i^0} = \#(i|x_i \neq0) $$
# **L1 èŒƒæ•°**
# $$ \large {\Vert x \Vert}_{1} =  \lgroup {\sum_{i}{\vert x_i \vert} }\rgroup $$
# **L2 èŒƒæ•°**
# $$ \large {\Vert x \Vert}_{2} =  \lgroup {\sum_{i}{\vert x_i \vert}^2 }\rgroup ^{\frac{1}{2}}$$
# 
# å¦å¤–è¿™é‡Œè¿˜å­˜åœ¨ç‰¹ä¾‹ï¼š
#  å½“ $ p -> \infty $ æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º $ L^{\infty} $èŒƒæ•°ï¼Œä¹Ÿè¢«ç§°ä¸ºâ€œmaximum normï¼ˆmaxèŒƒæ•°ï¼‰â€ï¼Œè¿™ä¸ªèŒƒæ•°è¡¨ç¤ºå‘é‡ä¸­å…·æœ‰æœ€å¤§å¹…åº¦çš„å…ƒç´ çš„ç»å¯¹å€¼ï¼š
# 
# $$ \large {\Vert x \Vert}^{\infty} =  \max_{i}{\vert x_i \vert} $$
# 
# [ä»¥ä¸Šèµ„æ–™éƒ¨åˆ†å‚è€ƒwiki](http://t.cn/RINHvvt)
# 
# ### 4.1ã€è®¡ç®—å‘é‡çš„èŒƒæ•°
# ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—ä¸€ä¸‹å‘é‡çš„å„ç§èŒƒæ•°ã€‚

# In[9]:


# DONE å®ç°è¿™é‡Œå‘é‡èŒƒæ•°è®¡ç®—çš„å‡½æ•°ï¼Œè¦æ±‚å¯ä»¥è®¡ç®—p = 0,1,2,3 ... æ— ç©· æƒ…å†µä¸‹çš„èŒƒæ•°

""" è®¡ç®—å‘é‡çš„èŒƒæ•°
    å‚æ•°
        x: å‘é‡ numpyæ•°ç»„ æˆ–è€…listæ•°ç»„
        p: èŒƒæ•°çš„é˜¶ï¼Œintå‹æ•´æ•°æˆ–è€…None
        infty: æ˜¯å¦è®¡ç®—maxèŒƒæ•°ï¼Œboolå‹å˜é‡ï¼ŒTrueçš„æ—¶å€™è¡¨ç¤ºè®¡ç®—maxèŒƒæ•°ï¼ŒFalseçš„æ—¶å€™è®¡ç®—pèŒƒæ•°
        
    è¿”å›
        å‘é‡çš„èŒƒæ•°ï¼Œfloatç±»å‹æ•°å€¼
        
    hint:
        1.ä½ éœ€è¦é¦–å…ˆåˆ¤æ–­inftyæ˜¯True or False, ç„¶ååˆ¤æ–­p æ˜¯å¦ä¸ºé›¶
        2.æ³¨æ„intç±»å‹å˜é‡åœ¨è®¡ç®—æ—¶å€™éœ€è¦è§„æ•´ä¸ºfloatç±»å‹
    
"""
def calc_Norm(x, p = 2 , infty = False):
    if infty:
        x_min = np.min(x)
        x_max = np.max(x)
        if (-x_min) > x_max:
            return float(-x_min)
        else:
            return float(x_max)
        
    if 0 == p:
        count_zero = 0
        if isinstance(x, list):
            count_zero = x.count(0)
        else:
            count_zero = (x.tolist()).count(0)
            
        result = float(len(x) - count_zero)
        return result
    
    p_float = float(p)
    result_sum = 0.0
    for item in x:
        result_sum = result_sum + pow(item, p_float)
    return pow(result_sum, 1/p_float)

      
            
            
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


# In[10]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_Norm')


# ### 4.2ã€è®¡ç®—çŸ©é˜µçš„èŒƒæ•°
# æˆ‘ä»¬ä¹Ÿéœ€è¦è¡¡é‡çŸ©é˜µçš„å¤§å°ï¼Œå¯¹äºçŸ©é˜µå¤§å°çš„è¡¡é‡åœ¨å¾ˆå¤šä¼˜åŒ–é—®é¢˜ä¸­æ˜¯éå¸¸é‡è¦çš„ã€‚è€Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæœ€å¸¸è§çš„åšæ³•æ˜¯ä½¿ç”¨Frobenius èŒƒæ•°(Frobenius norm)ï¼Œä¹Ÿç§°ä½œçŸ©é˜µçš„FèŒƒæ•°ï¼Œå…¶å®šä¹‰å¦‚ä¸‹ï¼š
# 
# $$ \large {\Vert A \Vert}_{F} =  \sqrt {\sum_{i,j}{\vert A_{i,j} \vert}^2 } $$
# 
# æˆ‘ä»¬è¿™é‡Œç»§ç»­æ¥è®¡ç®—ä¸€ä¸‹FèŒƒæ•°

# In[11]:


# DONE å®ç°è¿™é‡ŒçŸ©é˜µFrobeniusèŒƒæ•°è®¡ç®—çš„å‡½æ•°
""" è®¡ç®—å‘é‡çš„èŒƒæ•°
    å‚æ•°
        A: ç»™å®šçš„ä»»æ„äºŒç»´çŸ©é˜µ listæˆ–è€…numpyæ•°ç»„å½¢å¼
        
    è¿”å›
        çŸ©é˜µçš„FrobeniusèŒƒæ•°ï¼Œfloatç±»å‹æ•°å€¼
    
"""
def calc_Frobenius_Norm(A):
    list_A = None
    if isinstance(A, list):
        list_A = A
    else:
        list_A = A.tolist()
            
    temp_sum = 0.0
    for row in list_A:
        for item in row:
            temp_sum = temp_sum + pow(item, 2)
    return pow(temp_sum, 1/2)
            
            


# In[12]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_Frobenius_Norm')


# ### 4.3ã€è®¡ç®—çŸ©é˜µçš„æ¡ä»¶æ•°
# çŸ©é˜µçš„æ¡ä»¶æ•°(condition number)æ˜¯çŸ©é˜µï¼ˆæˆ–è€…å®ƒæ‰€æè¿°çš„çº¿æ€§ç³»ç»Ÿï¼‰çš„ç¨³å®šæ€§æˆ–è€…æ•æ„Ÿåº¦çš„åº¦é‡ï¼Œæˆ‘ä»¬è¿™é‡Œä¸ºäº†ç®€åŒ–æ¡ä»¶ï¼Œè¿™é‡Œåªè€ƒè™‘çŸ©é˜µæ˜¯å¥‡å¼‚çŸ©é˜µçš„æ—¶å€™ï¼Œå¦‚ä½•è®¡ç®—ä»¥åŠç†è§£æ¡ä»¶æ•°(condition number):
# 
# å½“çŸ©é˜µAä¸ºå¥‡å¼‚çŸ©é˜µçš„æ—¶å€™ï¼Œcondition numberä¸ºæ— é™å¤§ï¼›å½“çŸ©é˜µAéå¥‡å¼‚çš„æ—¶å€™ï¼Œæˆ‘ä»¬å®šä¹‰condition numberå¦‚ä¸‹ï¼š
# 
# $$ \large \kappa{(A)} =  {\Vert A \Vert}_F {\Vert A^{-1} \Vert}_F$$
# 
# [å¥‡å¼‚çŸ©é˜µï¼Œéå¥‡å¼‚çŸ©é˜µ](https://zh.wikipedia.org/wiki/%E9%9D%9E%E5%A5%87%E5%BC%82%E6%96%B9%E9%98%B5)
# 
# è®¡ç®—çŸ©é˜µçš„æ¡ä»¶æ•°

# In[13]:


""" è®¡ç®—çŸ©é˜µçš„æ¡ä»¶æ•°
    å‚æ•°
        A: ç»™å®šçš„ä»»æ„äºŒç»´çŸ©é˜µ listæˆ–è€…numpyæ•°ç»„å½¢å¼
        
    è¿”å›
        çŸ©é˜µçš„condition number,
    
"""
def calc_Condition_Number(A):
    numpy_A = None
    if isinstance(A, list):
        numpy_A = np.array(list)
    else:
        numpy_A = A
        
    inv_A = np.linalg.inv(numpy_A)
    frobns_A = calc_Frobenius_Norm(numpy_A)
    frobns_inv_A = calc_Frobenius_Norm(inv_A)
    return frobns_A * frobns_inv_A

# æˆ‘å°†testï¼Œæ‹¿å‡ºæ¥æ‰§è¡Œç»“æœ
# test_sample=np.array([[1,2],[2,4.0001]])
# calc_Condition_Number(test_sample)


# In[14]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_Condition_Number')


# ### (é€‰åš)4.4ã€æ¡ä»¶æ•°çš„ç†è§£ä¸åº”ç”¨
# 
# a. æœ‰å¦‚ä¸‹ä¸¤ä¸ª2*2çš„éå¥‡å¼‚çŸ©é˜µAå’ŒB:
# 
# $ A = \begin{bmatrix}
#      1   &2 \\
#      3   &4 \\
# \end{bmatrix} $ 
# 
# $ B = \begin{bmatrix}
#      1   &2 \\
#      2   &4.0001 \\
# \end{bmatrix}
# $
# 
# è®¡ç®—condition number(A), condition number(B);
# 
# b. æ ¹æ®ä¸Šé¢æ„é€ çš„çŸ©é˜µA,Båˆ†åˆ«è®¡ç®—çº¿æ€§ç³»ç»Ÿæ–¹ç¨‹ç»„çš„è§£$w$:
# 
# 
#    A $ \begin{bmatrix}w_{a1}\\w_{a2}\\ \end{bmatrix} $ = $ \begin{bmatrix}1\\2\\ \end{bmatrix} $, 
#     
#    B $ \begin{bmatrix}w_{b1}\\w_{b2}\\ \end{bmatrix} $ = $ \begin{bmatrix}1\\2\\ \end{bmatrix} $,
#    
#    A $ \begin{bmatrix}w_{a1}\\w_{a2}\\ \end{bmatrix} $ = $ \begin{bmatrix}{1.0001}\\{2.0001}\\ \end{bmatrix} $, 
#     
#    B $ \begin{bmatrix}w_{b1}\\w_{b2}\\ \end{bmatrix} $ = $ \begin{bmatrix}{1.0001}\\{2.0001}\\ \end{bmatrix} $.
# 
# 
# 
# c. è®¡ç®—å®Œæˆä¹‹åï¼Œæ¯”è¾ƒcondition numberå¤§å°ä¸çº¿æ€§ç³»ç»Ÿç¨³å®šæ€§ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä¸”ç»™å‡ºè§„å¾‹æ€§çš„æ€»ç»“ï¼›

# d. **é˜…è¯»ä¸æ€è€ƒ**: è€ƒè™‘æ›´ä¸ºé€šç”¨çš„ä¸€ç§æƒ…å†µï¼Œæˆ‘ä»¬è®¡ç®—ä¸€ä¸ªå…¸å‹çš„çº¿æ€§å›å½’ç³»ç»Ÿ: 
# 
# $$ Xw = b $$
# 
# å¯ä»¥ç®€å•æ¨å¯¼å¾—å‡ºå…¶é—­å¼è§£ä¸ºï¼š$ w=(X^TX)^{âˆ’1}X^Tb $ ï¼Œå¦‚æœ $X^TX$å¯é€†
# 
# æ¨å¯¼è¿‡ç¨‹ï¼š 
# 
# 1.ç­‰å¼ä¸¤è¾¹ä¹˜ä»¥$X^T$
# $$ X^TXw = X^Tb $$
# 2.ç­‰å¼ä¸¤è¾¹ä¹˜ä»¥$(X^TX)^{-1}$
# $$ (X^TX)^{-1}X^TXw = (X^TX)^{âˆ’1}X^Tb $$
# 3.å› ä¸º$A^{-1}A = I$ï¼Œä¸¤è¾¹çº¦å»å³å¯å¾—ï¼š
# $$ w=(X^TX)^{âˆ’1}X^Tb $$
# 
# 
# å½“æˆ‘ä»¬éœ€è¦æ‹Ÿåˆçš„æ•°æ®Xæ»¡è¶³æ•°æ®é‡è¿œè¿œå°äºç‰¹å¾æ•°ç›®çš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯XçŸ©é˜µçš„è¡Œæ•° << XçŸ©é˜µçš„åˆ—æ•°çš„æ—¶å€™ï¼Œå› ä¸º$X^TX$ä¸æ˜¯å¥‡å¼‚çŸ©é˜µï¼Œæ­¤æ—¶æ–¹ç¨‹ç»„ä¸å­˜åœ¨é—­å¼è§£ï¼›é‚£ä¹ˆæˆ‘ä»¬è¯¥å¦‚ä½•é‡æ–°æ„é€ $X^TX$ï¼Œä½¿å¾—è¯¥é—­å¼è§£æˆç«‹ï¼Ÿ
# 
# hint1. å•ä½çŸ©é˜µçš„condition numberæ˜¯æœ€ä½çš„ï¼Œæ˜¯æœ€ä¸ºç¨³å®šçš„ï¼›
# 
# hint2. å¦‚æœè¦ä½¿å¾—è¯¥ç³»ç»Ÿå­˜åœ¨é—­å¼è§£ï¼Œé‚£ä¹ˆå°±å¿…é¡»ä½¿å¾—æ±‚é€†è¿ç®—æ˜¯å¯ä»¥è¿›è¡Œçš„ï¼Œä¹Ÿå°±æ˜¯è¯´é‡æ–°æ„é€ çš„$X^TX$å¿…é¡»æ˜¯å¯é€†çš„æ–¹é˜µï¼›
# 
# hint3. é‡æ–°æ„é€ çš„æ–¹å¼å¯ä»¥æ˜¯åœ¨$X^TX$åŸºç¡€ä¸Šè¿›è¡ŒåŠ æˆ–è€…å‡æˆ–è€…ä¹˜é™¤ç›¸å…³çŸ©é˜µçš„æ“ä½œï¼›
# 
# ä¸€ç§å¯è¡Œçš„æ–¹å¼å°±æ˜¯ï¼š
# $$ w = (X^TX+\lambda I)^{âˆ’1}X^Tb $$
# 
# å®é™…ä¸Šæˆ‘ä»¬æœ€ä¸ºå¸¸ç”¨çš„[Ridge Regression](http://scikit-learn.org/stable/modules/linear_model.html)å’Œ L2èŒƒæ•°ä»¥åŠcondition numberä¹‹é—´æŸç§ç¨‹åº¦ä¸Šæ˜¯å¯ä»¥ç›¸äº’æ¨å¯¼çš„ï¼š
# 
# é¦–å…ˆï¼ŒRidge Regressionçš„æŸå¤±å‡½æ•°ä¸ºï¼š
# $$ J_w = min({\Vert Xw -y \Vert}^2 + \alpha {\Vert w \Vert}^2) $$
# æˆ‘ä»¬å±•å¼€è¿™ä¸ªæŸå¤±å‡½æ•°ï¼š
# $$ {\Vert Xw -y \Vert}^2 + \alpha {\Vert w \Vert}^2  =  (Xw -y)^T (Xw-y) + \alpha w^Tw$$
# ç”±äºè¿™é‡Œæ˜¯ä¸€ä¸ªå‡¸å‡½æ•°ï¼Œæˆ‘ä»¬ä»¤å¯¼æ•°ç­‰äºé›¶ï¼Œå³ä¸ºæœ€å°å€¼çš„è§£ï¼Œæ±‚å¯¼å¯å¾—ï¼š
# $$ X^T (Xw-y) + \alpha w = 0 $$
# 
# æ•´ç†å³å¯å¾—åˆ°ï¼š
# $$ w = (X^TX+\lambda I)^{âˆ’1}X^Tb $$

# ## 5ã€SVD
# 
# [SVD](https://en.wikipedia.org/wiki/Singular-value_decomposition)æ˜¯Singular value decompositionçš„ç¼©å†™ï¼Œç§°ä¸ºå¥‡å¼‚å€¼åˆ†è§£ï¼Œæ˜¯åˆ†è§£çŸ©é˜µçš„ä¸€ç§æ–¹å¼ï¼Œä¼šå°†çŸ©é˜µåˆ†è§£ä¸ºå¥‡å¼‚å‘é‡ï¼ˆsingular vectorï¼‰å’Œå¥‡å¼‚å€¼ï¼ˆsingular valueï¼‰ï¼Œåˆ†è§£çš„æ„ä¹‰å…¶å®å¾ˆæ˜ç¡®ï¼Œå°±æ˜¯æƒ³å°†ä¸€ä¸ªå¾ˆå¤§å¾ˆå¤æ‚çš„çŸ©é˜µï¼Œç”¨æ›´å°æ›´ç®€å•çš„å‡ ä¸ªå­çŸ©é˜µçš„ç›¸ä¹˜æ¥è¡¨ç¤ºï¼Œè¿™äº›å°çŸ©é˜µæè¿°çš„æ˜¯çŸ©é˜µçš„é‡è¦çš„ç‰¹æ€§ã€‚
# 
# é‚£ä¹ˆSVDå…·ä½“çš„æ•°å­¦è¡¨è¾¾æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
# 
# å‡è®¾æœ‰ä¸€ä¸ªçŸ©é˜µCï¼Œæˆ‘ä»¬å¯ä»¥å°†çŸ©é˜µCåˆ†è§£ä¸ºä¸‰ä¸ªçŸ©é˜µçš„ä¹˜ç§¯ï¼š
# <img src="images/svd.png" width="480">
# 
# $$\large C = UDV^{T}$$
# 
# 
# å¦‚æœCæ˜¯ä¸€ä¸ªm x nçš„çŸ©é˜µï¼Œé‚£ä¹ˆUæ˜¯ä¸€ä¸ªm x mçš„çŸ©é˜µï¼ŒDæ˜¯ä¸€ä¸ªm x nçš„çŸ©é˜µï¼ŒVæ˜¯ä¸€ä¸ªn x nçš„çŸ©é˜µï¼Œè¿™äº›å°çŸ©é˜µå¹¶ä¸æ˜¯æ™®æ™®é€šé€šçš„çŸ©é˜µï¼ŒUå’ŒVéƒ½å®šä¹‰ä¸ºæ­£äº¤çŸ©é˜µï¼Œè€ŒDå®šä¹‰ä¸ºå¯¹è§’çŸ©é˜µã€‚
# 
# SVDæœ€å¸¸ç”¨çš„åšæ³•å°±æ˜¯ç”¨æ¥è¿›è¡Œç‰¹å¾çš„é™ç»´ä»¥åŠçŸ©é˜µçš„ä½ç§©é‡æ„ï¼Œä¾‹å¦‚è¿™é‡Œåˆ†åˆ«å–çŸ©é˜µUã€Dã€VTçš„å‰kåˆ—ï¼Œå¦‚å›¾ç¤ºä¸­çš„ç™½è‰²éƒ¨åˆ†ï¼Œç„¶åé‡æ–°è®¡ç®—æ–°çš„CçŸ©é˜µï¼Œå³ä¸ºkç»´åº¦ä¸‹çš„çŸ©é˜µé‡æ„ï¼Œè¿™ç§æ–¹æ³•è¢«å¹¿æ³›åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†[LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis)ã€æ¨èç³»ç»Ÿ[SVD++,FM,FFM](https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html)ç­‰é¢†åŸŸï¼Œå¦‚æœ‰å…´è¶£å¯ä»¥ç»§ç»­å‚è€ƒé“¾æ¥ç›¸å…³èµ„æ–™ã€‚
# <img src="images/svd_decompostion.png" width="480">
# 
# 
# å…·ä½“è®¡ç®—UDVçš„ç®—æ³•ä¸æ˜¯æˆ‘ä»¬è¿™ä¸ªé¡¹ç›®çš„å…³é”®ï¼Œæˆ‘ä»¬åªéœ€ä½¿ç”¨numpyå¾—å‡ºç»“æœå³å¯ï¼Œä¸‹é¢çš„ä¹ é¢˜ï¼Œå°†ä¼šå¸¦ä½ ä½“ä¼šSVDçš„æŸä¸€åº”ç”¨åœºæ™¯ã€‚
# 
# æç¤ºï¼šæˆ‘ä»¬ä¼šéœ€è¦ä½¿ç”¨[numpy.linalg](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html)ç›¸å…³å‡½æ•°ã€‚
# 
# ### 5.1ã€ä½¿ç”¨numpyå»è®¡ç®—ä»»æ„çŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£ï¼š

# In[15]:


""" è®¡ç®—ä»»æ„çŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£
    å‚æ•°
        A: ç»™å®šçš„ä»»æ„äºŒç»´çŸ©é˜µ listæˆ–è€…numpyæ•°ç»„å½¢å¼ 
        
    è¿”å›
        ä½¿ç”¨numpy.linalgç›¸å…³å‡½æ•°ï¼Œç›´æ¥è¿”å›åˆ†è§£ä¹‹åçš„çŸ©é˜µU,D,V
        ï¼ˆå¯ä»¥å°è¯•ä¸€ä¸‹ä½¿ç”¨np.shapeä¸€ä¸‹åˆ†è§£å‡ºæ¥çš„Uï¼ŒDï¼ŒVTï¼Œä¼šå‘ç°ç»´åº¦è·Ÿæˆ‘ä»¬ä¸Šé¢è®²è§£æ‰€æè¿°çš„ä¸åŒï¼Œ
        æš‚æ—¶ä¸ç”¨ç®¡ä»–ç›´æ¥è¿”å›npæ±‚è§£å‡ºçš„Uï¼ŒDï¼ŒVTå³å¯ï¼‰
    
"""
def calc_svd(A):
    numpy_A = None
    if isinstance(A, list):
        numpy_A = np.array(A)
    else:
        numpy_A = A
        
    return np.linalg.svd(numpy_A, full_matrices=True)


# In[16]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_svd')


# ### (é€‰åš) 5.2ã€åˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£å¯¹çŸ©é˜µè¿›è¡Œé™ç»´

# In[17]:


# TODO åˆ©ç”¨SVDè¿›è¡Œå¯¹äºçŸ©é˜µè¿›è¡Œé™ç»´

""" åˆ©ç”¨SVDè¿›è¡Œå¯¹äºçŸ©é˜µè¿›è¡Œé™ç»´
    å‚æ•°
        A: ç»™å®šçš„ä»»æ„äºŒç»´çŸ©é˜µ listæˆ–è€…numpyæ•°ç»„å½¢å¼ shapeä¸º(m,n)
        topk: é™ç»´çš„ç»´åº¦ (m,n) -> (m,topk)
        
    è¿”å›
        é™ç»´åçš„çŸ©é˜µ (m, topk)
    
    hint
    1. å¯¹è§’çŸ©é˜µDå­˜åœ¨ä¸€ä¸ªè¾ƒä¸ºæ˜æ˜¾çš„ç‰¹æ€§ï¼Œå°±æ˜¯Dçš„å¯¹è§’çº¿å…ƒç´ æ˜¯é€’å‡çš„ï¼Œè¿™äº›å…ƒç´ å®é™…ä¸Šæ˜¯è¡¡é‡äº†æ‰€åˆ†è§£çš„çŸ©é˜µU,Vçš„åˆ—å‘é‡çš„é‡è¦æ€§
    2. å› æ­¤æˆ‘ä»¬å¸¸è¯´çš„svdé™ç»´å°±æ˜¯åˆ©ç”¨é€‰å–çš„å‰topkå¤§çš„å¯¹è§’çº¿çŸ©é˜µå…ƒç´ è¿›è¡Œæ„é€ æ–°çš„é™ç»´çŸ©é˜µ
    3. Uçš„æŒ‰ç…§å‰topkæˆªå–çš„åˆ—å‘é‡ * topkæˆªå–çš„å¯¹è§’çŸ©é˜µ å³ä¸ºæ–°çš„é™ç»´åçš„çŸ©é˜µ
    
"""
def calc_svd_decompostion(A, topk = 2):
    pass


# In[18]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_svd_decompostion')


# ### (é€‰åš) 5.3ã€åˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£å¯¹çŸ©é˜µè¿›è¡Œé™ç»´åé‡æ„

# In[19]:


""" åˆ©ç”¨SVDè¿›è¡Œå¯¹äºçŸ©é˜µè¿›è¡Œé™ç»´
    å‚æ•°
        A: ç»™å®šçš„ä»»æ„äºŒç»´çŸ©é˜µ listæˆ–è€…numpyæ•°ç»„å½¢å¼ shapeä¸º(m,n)
        topk: é™ç»´çš„ç»´åº¦ (m,n) -> (m,topk)
        
    è¿”å›
        é™ç»´é‡æ„åçš„çŸ©é˜µ (m, n)
    hint
        è¿™é‡Œé™¤äº†é™ç»´çŸ©é˜µå¤–ï¼Œå¦å¤–ä¸€ä¸ªè¾ƒä¸ºå¸¸è§çš„åº”ç”¨å°±æ˜¯å¯¹çŸ©é˜µè¿›è¡Œé‡æ„ï¼Œå…·ä½“çš„åšæ³•ç±»ä¼¼å‰é¢çš„æ€è·¯
        1. é€‰å–å¯¹åº”çš„Uï¼ŒDï¼ŒVçš„topkå‘é‡
        2. Uçš„æŒ‰ç…§å‰topkæˆªå–çš„åˆ—å‘é‡ * topkæˆªå–çš„å¯¹è§’çŸ©é˜µ * V^TæŒ‰ç…§å‰topkæˆªå–çš„è¡Œå‘é‡(æ³¨æ„è¿™é‡Œæ˜¯Vçš„è½¬ç½®,å› ä¸ºåˆ†è§£å¾—åˆ°çš„æ˜¯V^T)
        
"""
def calc_svd_reconsitution(A, topk = 2):
    pass


# In[20]:


get_ipython().run_line_magic('run', '-i -e test.py LinearRegressionTestCase.test_calc_svd_reconsitution')


# ### (é€‰åš) 5.4ã€è®¡ç®—ä¸åŒé™ç»´å¤§å°é‡æ„çŸ©é˜µçš„FrobeniusèŒƒæ•°æŸå¤±
# 
# å®šä¹‰çŸ©é˜µ$A$ä»¥åŠä½¿ç”¨SVDé™ç»´ï¼ˆé™ç»´å¤§å°ä¸ºk)åˆ†è§£åçš„é‡æ„çŸ©é˜µ$A_k$ï¼Œåˆ™è¿™é‡Œçš„FèŒƒæ•°æŸå¤±å®šä¹‰å¦‚ä¸‹ï¼š
# 
#   $$ \Large Loss_{F} = {\Vert A - A_k \Vert}_F $$
#   
# è¿™é‡Œéœ€è¦ç¼–ç æ±‚å‡ºå¯¹äºç»™å®šçš„çŸ©é˜µA åˆ†åˆ«åœ¨ä¸åŒçš„é™ç»´å¹…åº¦ä¸‹é‡æ„åçš„FèŒƒæ•°æŸå¤±ï¼Œå¹¶ä¸”ä½œå‡ºæŸå¤±å¤§å°éšç€é™ç»´å¤§å°çš„å˜åŒ–å›¾ï¼š

# In[21]:


## ä¸è¦ä¿®æ”¹è¿™é‡Œï¼
import numpy as np
from sklearn.datasets import load_boston  
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
A = load_boston()['data']  # è½½å…¥boston house æ•°æ®é›†
print(A.shape)


# In[22]:


loss_hist = []
for topk in range(1,13):
    # 5.4 TODO 
    ### 1.è®¡ç®—ç›¸åº”çš„SVD topké™ç»´åçš„é‡æ„çŸ©é˜µï¼Œéœ€å®ç°calc_svd_reconsitution
    ### 2.è®¡ç®—å¯¹åº”çš„FèŒƒæ•°æŸå¤±ï¼Œå¹¶å­˜å‚¨lossæ”¾å…¥loss_histåˆ—è¡¨ä¸­


### ç”»å‡ºFæŸå¤±éšç€é™ç»´å¤§å°çš„å˜åŒ–å›¾
### xåæ ‡ä¸ºå¯¹åº”çš„é™ç»´å¤§å°ï¼Œyåæ ‡ä¸ºå¯¹åº”çš„FæŸå¤±
plt.plot(range(1,13),loss_hist,'r--')
plt.xlabel('decomposition size')
plt.ylabel('F Loss')


# ### 5.5ã€SVDçš„æœ‰è¶£åº”ç”¨
# ä¸ºäº†è¿™ä¸ªä¹ é¢˜æˆ‘å‡†å¤‡äº†ä¸¤å¼ å›¾ï¼Œå‚è§é¡¹ç›®æ–‡ä»¶å¤¹ä¸‹çš„test_girl.jpgå’Œtest_boy.jpegï¼Œè‡ªé€‰ä¸€å¼ ï¼Œä½ éœ€è¦
# - éœ€è¦ä½¿ç”¨ `PIL` åŠ è½½ä½ æ‰€é€‰æ‹©çš„å›¾åƒï¼ˆ[æ–‡æ¡£](https://pillow.readthedocs.io/en/latest/reference/Image.html)ï¼‰,æ‰€ä»¥è®°å¾—å¯¼å…¥éœ€è¦çš„åŒ…ï¼ˆæ¨¡å—ï¼‰
# - ä½¿ç”¨Imageçš„[convertæ–¹æ³•](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.convert)å°†å›¾åƒå˜ä¸ºç°åº¦å›¾
# - å°†convertåçš„ç»“æœè½¬æ¢æˆnp.array,éœ€ç”¨åˆ°[Image.getdataæ–¹æ³•](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.getdata)æ¥è¯»å–å›¾ç‰‡æ¯ä¸ªpixelçš„æ•°æ®ï¼Œç‰¹åˆ«æ³¨æ„ä¸€ä¸‹ï¼Œå¯¹äºå½©è‰²çš„å›¾æ¥è¯´ï¼Œå³ä½¿æˆ‘ä»¬è½¬ä¸ºäº†ç°åº¦å›¾ï¼Œä½†æ¯ä¸€ä¸ªpixelè¿˜æ˜¯ç”±RGBä¸‰ä¸ªç»´åº¦ç»„æˆï¼Œæ‰€ä»¥åœ¨getdataæ—¶ï¼Œbandéœ€è¦è®¾å®šä¸ºæŸä¸€ä¸ªé¢œè‰²indexï¼Œæ¯”å¦‚band = 0ï¼Œè¿™æ ·åªç”¨Rè¿™ä¸ªç»´åº¦çš„æ•°æ®ã€‚ç”¨è¿™ä¸ªæ–¹æ³•æ¥ä¿è¯å›¾ç‰‡çš„æ¯ä¸ªpixelåªå æœ‰ä¸€ä¸ªå•å…ƒçš„ç©ºé—´ã€‚
# - å› ä¸ºæˆ‘ä»¬è½¬np.arrayæ—¶ç ´åäº†åŸæœ‰å›¾å½¢çš„æ ·å­ï¼Œå˜æˆäº†ä¸€ä¸ªä¸€ç»´æ•°æ®ï¼Œæˆ‘ä»¬è¦å°†è½¬æ¢åçš„np.arrayæ¢å¤åˆ°å›¾ç‰‡åº”æœ‰çš„sizeï¼Œè½¬æ¢åï¼Œå¯ä»¥shapeç¡®è®¤ä¸‹æ˜¯å¦ä¸æœ€å¼€å§‹è½¬å‡ºçš„ç°åº¦å›¾çš„sizeä¸€è‡´ï¼Œæ³¨æ„å›¾çš„sizeæ˜¯ï¼ˆå®½ï¼Œé«˜ï¼‰ï¼Œè€Œå®½å¯¹åº”array.shapeçš„åº”è¯¥æ˜¯åˆ—ï¼Œè€Œé«˜å¯¹åº”çš„æ˜¯è¡Œï¼Œåˆ«å¼„åäº†ã€‚
# - ä½¿ç”¨ä¸Šæ–¹å®ç°çš„calc_svdå‡½æ•°è®¡ç®—ä¸Šä¸€æ­¥è®¡ç®—å‡ºçš„np.arrayæ•°æ®ï¼Œèµ‹å€¼ç»™å˜é‡ï¼šU,D,VT
# - æ‰“å°å‡ºU,D,VTçš„shapeå½¢çŠ¶ï¼Œå°¤å…¶æ³¨æ„è§‚å¯ŸDçš„shape
# - åœ¨Uï¼ŒVTï¼ŒDå˜é‡æˆåŠŸå®ç°çš„æƒ…å†µä¸‹ï¼Œè¿è¡Œæµ‹è¯•ç¨‹åºçœ‹æ•ˆæœ

# In[ ]:


# 5.5 DONE
im = Image.open('test_girl.jpg') 
im_w, im_h = im.size
im_gray = im.convert(matrix="L")
im_array = np.array(list(im_gray.getdata(0))).reshape(im_h, im_w)
U, D, VT = calc_svd(im_array)
print(U.shape)
print(D.shape)
print(VT.shape)


# In[ ]:


#è¯·åœ¨Uï¼ŒDï¼ŒVå˜é‡å®Œæˆçš„æƒ…å†µä¸‹è°ƒç”¨æ­¤æµ‹è¯•ç¨‹åºï¼Œä¸è¦ä¿®æ”¹æ­¤å¤„
plt.figure(figsize=(16,6))
for i,topk in enumerate([5, 10, 15, 20, 30, 50]):
    reconstimg = np.matrix(U[:, :topk]) * np.diag(D[:topk]) * np.matrix(VT[:topk, :])
    plt.subplot(231+i)
    plt.imshow(reconstimg, cmap='gray')
    title = "n = %s" % ((i+1)*5)
    plt.title(title)
plt.show()


# ç›¸å…³ç»§ç»­æ·±å…¥å­¦ä¹ çš„èµ„æ–™ï¼š
# 1. [æœºå™¨å­¦ä¹ ä¸ä¼˜åŒ–](http://freemind.pluskid.org/series/mlopt/)
# 2. [PCAä¸SVDçš„åŒºåˆ«](https://www.zhihu.com/question/40043805/answer/138429562)
# 3. [SVDåœ¨é™ç»´ä¸­çš„åº”ç”¨](https://www.cnblogs.com/pinard/p/6251584.html)
# 4. [SVDåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨](https://blog.csdn.net/pipisorry/article/details/42560331)
# 5. [SVDåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨](https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html)
# 6. [ã€ŠElements of Statistical Learningã€‹Trevor Hastie, Robert Tibshirani, and Jerome Friedman](https://web.stanford.edu/~hastie/ElemStatLearn//)
